<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Subhrajyoti Dasgupta</title>
  
  <meta name="author" content="Subhrajyoti Dasgupta">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Subhrajyoti Dasgupta</name></br>
                Learning with machines.<br>
              </p>
              <p>I am a Computer Vision researcher from India. I'm majorly interested in audio-visual learning, visual scene understanding and computational photography.
              </p>
              <p>
                I work under the guidance of <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Prof. Ujjwal Bhattacharya</a> at the CVPR Unit, <a target=”_blank” href="https://www.isical.ac.in">Indian Statistical Institute, Kolkata.</a> Earlier, I have also completed a short stint at <a target=”_blank” href="http://www.barc.gov.in/">Bhabha Atomic Research Center, Mumbai</a> where I worked on Devanagari text recognition in constrained settings. I graduated from Amity University with a <i>First Class with Distinction</i> Bachelor's degree in Computer Science and Engineering. Previously, I have worked on audio-visual co-segmentation, audio-visual summarization and medical signal processing.
              </p>
              <p style="text-align:center">
                <a target=”_blank” href="mailto:subhrajyotidg@gmail.com">Email</a> &nbsp/&nbsp
                <a target=”_blank” href="data/Subhrajyoti_CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a target=”_blank” href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <!-- <a target=”_blank” href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a target=”_blank” href="https://www.linkedin.com/in/subhrajyoti-dasgupta/">Linkedin</a> &nbsp/&nbsp
                <a target=”_blank” href="https://twitter.com/subhrajyotidg">Twitter</a> &nbsp/&nbsp
                <a target=”_blank” href="https://github.com/subhrajyotidasgupta/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a target=”_blank” href="images/Subhrajyoti.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Subhrajyoti_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Updates</heading>
              <p>
                <b>[Nov '21]:</b> Presented <i>AudViSum</i> at BMVC 2021!<a target=”_blank” href="https://www.youtube.com/watch?v=Hier-zMWcc0">[Presentation]</a> </br> 
                <b>[Oct '21]:</b> <i>AudViSum</i> accepted at BMVC 2021! </br> 
                <b>[Sep '21]:</b> Presented <i>Listen to the Pixels</i> at ICIP 2021! <a target=”_blank” href="https://www.youtube.com/watch?v=xUwzSQaQ9oQ">[Presentation]</a> </br> 
                <b>[May '21]:</b> <i>Listen to the Pixels</i> accepted at ICIP 2021! </br>
                <b>[Jan '21]:</b> Presented <i>CardioGAN</i> at ICPR 2020! <a target=”_blank” href="hhttps://www.youtube.com/watch?v=BmOG9IMXFUU">[Presentation]</a> </br> 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>

        <script>
          function myFunction(pub_name) {
              var x = document.getElementById(pub_name);
              if (x.style.display === 'none') {
                  x.style.display = 'block';
              } else {
                  x.style.display = 'none';
              }
        }
        </script>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mipnerf_ipe_yellow.png' width="160">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="http://jonbarron.info/mipnerf">
                <papertitle>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a target=”_blank” href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a target=”_blank” href="http://matthewtancik.com/">Matthew Tancik</a>, <br>
              <a target=”_blank” href="https://phogzone.com/">Peter Hedman</a>,
              <a target=”_blank” href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a target=”_blank” href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a target=”_blank” href="http://jonbarron.info/mipnerf">project page</a>
              /
              <a target=”_blank” href="https://arxiv.org/abs/2103.13415">arXiv</a>
              /
              <a target=”_blank” href="https://youtu.be/EpH175PY1A0">video</a>
							/
              <a target=”_blank” href="https://github.com/google/mipnerf">code</a>
              <p></p>
              <p>NeRF is aliased, but we can anti-alias it by casting cones and prefiltering the positional encoding function.</p>
            </td>
          </tr>  -->

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/audvisum.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/audvisum.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">
              <papertitle>AudViSum: Self-Supervised Deep Reinforcement Learning for diverse Audio-Visual Summary generation</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://scholar.google.co.in/citations?user=CEdJKCIAAAAJ&hl=en">Sanjoy Chowdhury</a>, 
              <a target=”_blank” href="https://scholar.google.com/citations?user=FcEMgBgAAAAJ&hl=en">Aditya P. Patra</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
							<em>BMVC</em>, 2021 
              <br>
              <!-- <a target=”_blank” href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a target=”_blank” href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> -->
              <!-- / -->
              <a target=”_blank” href="https://www.youtube.com/watch?v=Hier-zMWcc0">Presentation</a>
              /
              <a href="javascript:void(0);" onclick="myFunction('bmvc21_0_bib')">BibTex</a>
              <p></p>
              <p>Generating representative and diverse audio-visual summaries by exploiting both the audio and visual modalities, unlike prior works. Also presented a new dataset on TVSum and OVP with audio and visual annotations.</p>
              <div id="bmvc21_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @inproceedings{chowdhury2021audvisum, </br>
                    title={AudViSum: Self-Supervised Deep Reinforcement Learning for Diverse Audio-Visual Summary Generation.}, </br>
                    author={Chowdhury, Sanjoy and Patra, Aditya P. and Dasgupta, Subhrajyoti and Bhattacharya, Ujjwal},</br>
                    booktitle={BMVC},</br>
                    <!-- pages={245},</br> -->
                    year={2021}</br>
                  }
              </font></div>
            </td>



          <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/icip_21.png" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/icip_21.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }
                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
              <script>
              $(document).ready(function(){
                $("#toggle_click_icip20").click(function(){
                  $("#toggle_icip20").show();
                  // $("#div2").fadeToggle("slow");
                  // $("#div3").fadeToggle(3000);
                });
              });
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://ieeexplore.ieee.org/document/9506019">
                <papertitle>Listen to the Pixels</papertitle>
              </a>
              <br>
              <a target=”_blank” href="https://scholar.google.co.in/citations?user=CEdJKCIAAAAJ&hl=en">Sanjoy Chowdhury</a>,
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
							<em>ICIP</em>, 2021
              <br>
              <a target=”_blank” href="https://www.youtube.com/watch?v=xUwzSQaQ9oQ">Presentation</a> /
              <a href="javascript:void(0);" onclick="myFunction('icip21_0_bib')">BibTex</a>
              <p></p>
              <p>Audio-visual co-segmentation and sound source separation using a novel multimodal fusion mechanism, also addressing partially occluded sound source separation and co-segmentation for multiple but similar sound sources.
              </p>
              <div id="icip21_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:  #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @INPROCEEDINGS{9506019,</br>
                    author={Chowdhury, Sanjoy and Dasgupta, Subhrajyoti and Das, Sudip and Bhattacharya, Ujjwal},</br>
                    booktitle={2021 IEEE International Conference on Image Processing (ICIP)}, </br>
                    title={Listen To The Pixels}, </br>
                    year={2021},</br>
                    pages={2568-2572},</br>
                    doi={10.1109/ICIP42928.2021.9506019}</br>
                  }
              </font></div>
            </td>
          </tr> 


          <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cardiogan.png' width="160"></div>
                <img src='images/cardiogan.png' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
              <script>
              $(document).ready(function(){
                $("#toggle_click_icip20").click(function(){
                  $("#toggle_icip20").fadeToggle();
                  // $("#div2").fadeToggle("slow");
                  // $("#div3").fadeToggle(3000);
                });
              });
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9412905">
                <papertitle>CardioGAN: An Attention-based Generative Adversarial Network for Generation of Electrocardiograms</papertitle>
              </a>
              <br>
              <strong>Subhrajyoti Dasgupta</strong>,
              <a target=”_blank” href="https://sudip.info/">Sudip Das</a>,
              <a target=”_blank” href="https://www.isical.ac.in/~ujjwal/">Ujjwal Bhattacharya</a>
              <br>
							<em>ICPR</em>, 2020
              <br>
              <a target=”_blank” href="https://www.youtube.com/watch?v=BmOG9IMXFUU">Presentation</a> /
              <a href="javascript:void(0);" onclick="myFunction('icpr20_0_bib')">BibTex</a>
              <p></p>
              <p>
                Generating synthetic ECGs, for easy sharing without risk of privacy breach, using an Attention-based Generative Adversarial Network.
              </p>
              <div id="icpr20_0_bib" style="font-family:Courier;font-size: 12px; margin: 0px;padding: 10px;display:none;min-width:350px;background-color:   #F0F0F0;border-radius: 10px;"><font size="2">
                <br>
                  @INPROCEEDINGS{9412905,<br> 
                    author={Dasgupta, Subhrajyoti and Das, Sudip and Bhattacharya, Ujjwal},<br>
                    booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, <br>
                    title={CardioGAN: An Attention-based Generative Adversarial Network for Generation of Electrocardiograms}, <br>
                    year={2021},<br>
                    pages={3193-3200},<br>
                    doi={10.1109/ICPR48806.2021.9412905}<br>
                }
            </td>
          </tr> 


          
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom: 10px; width:100%;vertical-align:middle">
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/devanagari.png' width="160"></div>
                <img src='images/devanagari.png' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">
                <papertitle>Detection and Recognition of Handwritten Text written in Devanagari script from documents</papertitle>
              </a>
              <br>
              <p>
                While there exists large literature to detect and recognise English text in natural scenes and documents, during the time of this study, regional languages were not very largely studied. In this project done at <a target=”_blank” href="http://www.barc.gov.in/">Bhabha Atomic Research Center, Mumbai</a>, dealt with a huge shortage of data and the nuances in the Devanagari script. Learning strategies for constrained settings like few-shot learning, transfer learning were used to develop the project. The project was implemented using Keras and Python. A great deal of OpenCV, Matplotlib and other scientific tools were also used.
              </p>
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">Code</a>
            </td>
          </tr>           
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/cern.jpg' width="160"></div>
                <img src='images/cern.jpg' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a target=”_blank” href="https://github.com/subhrajyotidasgupta/DevanagariHTR">
                <papertitle>Studying ways to solve challenges faced by the LHC (CERN) with Machine Learning</papertitle>
              </a>
              <br>
              <p>
                A humongous amount of data is produced by the <a target=”_blank” href="https://home.cern/science/accelerators/large-hadron-collider">LHC</a> per day. This data needs to be processed and used efficiently for further research. This study was on how Machine Learning can be implemented for particle identification, particle track reconstruction, clustering of particles based on similarity, and identifying rare decays. A study on the proposed <a target=”_blank” href="https://ship.web.cern.ch/">SHiP</a> experiment, with the scope of Machine Learning in it, was also done.
              </p>
            </td>
          </tr> 


          
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Template Credits: <a style="text-align:center;font-size:small;" href="https://jonbarron.info/">Dr. Jon Barron</a>
                
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
